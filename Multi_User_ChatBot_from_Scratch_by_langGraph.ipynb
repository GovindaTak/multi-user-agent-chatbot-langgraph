{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Multi-User ChatBot from Scratch by langGraph\n",
        "\n",
        "Tasks :- 1) build simple agent using langgraph\n",
        "\n",
        "2) build the agent with tools (WebSearch and Weather api)\n",
        "\n",
        "3) build the multi user chatbot agent with tools.\n"
      ],
      "metadata": {
        "id": "lXhbBvON-GSB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "orjJPWJ-O4hr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54eff1fe-2e82-41de-eaac-7bcc73ffdf85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (0.28.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx) (4.15.0)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.76)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.28)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.9)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.6.8-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.76)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.11.9)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.4.28)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
            "Downloading langgraph-0.6.8-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "Successfully installed langgraph-0.6.8 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.9 ormsgpack-1.10.0\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.30-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.3.76)\n",
            "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.43)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain_community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.10.1)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.28)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain_community) (0.3.11)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain_community) (2.11.9)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain_community) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain_community) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain_community) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain_community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.3.1)\n",
            "Downloading langchain_community-0.3.30-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain_community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain_community-0.3.30 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.33-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.76 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.3.76)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.104.2 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (1.108.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.11.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (0.4.28)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (25.0)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (2.11.9)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (0.11.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.5)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.104.2->langchain_openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain_openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain_openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain_openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.76->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_openai) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_openai) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.76->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.76->langchain_openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.76->langchain_openai) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.5.0)\n",
            "Downloading langchain_openai-0.3.33-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain_openai\n",
            "Successfully installed langchain_openai-0.3.33\n"
          ]
        }
      ],
      "source": [
        "!pip install httpx\n",
        "!pip install langchain\n",
        "!pip install langgraph\n",
        "!pip install langchain_community\n",
        "!pip install langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "OPENAI_API_KEY=getpass(\"enter the openai key:-\")\n",
        "TAVILY_API_KEY=getpass(\"enter the tavily api key:-\")\n",
        "WEATHER_API_KEY=getpass(\"enter the weather api key:-\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6_b7sap_dYs",
        "outputId": "5adc931f-a4ec-4b49-fb17-f4c3c3bddf69"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "enter the openai key:-路路路路路路路路路路\n",
            "enter the tavily api key:-路路路路路路路路路路\n",
            "enter the weather api key:-路路路路路路路路路路\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"]=OPENAI_API_KEY\n",
        "os.environ[\"WEATHER_API_KEY\"]=WEATHER_API_KEY\n",
        "os.environ[\"TAVILY_API_KEY\"]=TAVILY_API_KEY"
      ],
      "metadata": {
        "id": "-iIzfNbcAOXg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "llm=ChatOpenAI(model=\"gpt-4o\",temperature=0)"
      ],
      "metadata": {
        "id": "CSgFu8p2A4kX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1) build simple agent using langgraph"
      ],
      "metadata": {
        "id": "ekjFwaAFNQVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph\n",
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "  messages:Annotated[list,add_messages]\n",
        "\n",
        "graph=StateGraph(GraphState)\n"
      ],
      "metadata": {
        "id": "YTbvST46BIQs"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatgpt(state:GraphState):\n",
        "  return {\"messages\":[llm.invoke(state[\"messages\"])]}"
      ],
      "metadata": {
        "id": "n7ACBLkkOsg-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph.add_node(\"llm\",chatgpt)\n",
        "graph.set_finish_point(\"llm\")\n",
        "graph.set_entry_point(\"llm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlwXADagPYyZ",
        "outputId": "ea4ba190-a098-4a5a-91f1-084d111bd64c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7fd52ebde540>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent=graph.compile()"
      ],
      "metadata": {
        "id": "ZqVHpM4sQCJG"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response=agent.invoke({\"messages\":(\"user\",\"give me syllabus of langgraph.\")})"
      ],
      "metadata": {
        "id": "HJdXc7_9QyA4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response[\"messages\"][-1].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FncJe83ASRc6",
        "outputId": "02fb7e69-5a45-4b85-987b-3939c4da9233"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It seems like you might be referring to a specific course or subject called \"LangGraph,\" but there isn't a widely recognized course or subject by that name as of my last update. It's possible that \"LangGraph\" could be a specialized course offered by a particular institution or a new subject that has emerged after my last update.\n",
            "\n",
            "To get the most accurate and detailed syllabus for \"LangGraph,\" I recommend the following steps:\n",
            "\n",
            "1. **Institution Website**: Check the website of the institution offering the course. They often have detailed syllabi available for students.\n",
            "\n",
            "2. **Course Catalog**: Look for a course catalog or academic bulletin from the institution. These documents typically include course descriptions and syllabi.\n",
            "\n",
            "3. **Contact the Instructor**: If you have contact information for the instructor or department offering the course, reaching out directly can provide you with the most specific and up-to-date information.\n",
            "\n",
            "4. **Online Platforms**: If \"LangGraph\" is a course offered through an online learning platform, such as Coursera, edX, or Udemy, you can search for it directly on those platforms.\n",
            "\n",
            "If you can provide more context or details about \"LangGraph,\" I might be able to offer more specific guidance or suggestions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__We can easily see that our llm not have data on this topic let's build the agent with web search capability.__"
      ],
      "metadata": {
        "id": "8t5gq6W7SqOl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2) build the agent with tools (WebSearch and Weather api)"
      ],
      "metadata": {
        "id": "uCDZPPIzS6E-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_core.tools import tool\n",
        "import requests\n",
        "\n",
        "tv_search=TavilySearchResults(max_results=3,search_depth='advanced',max_tokens=10000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9UM_rJJSW0Q",
        "outputId": "ae445222-a66f-40b9-96c4-603b2007d11c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-998168330.py:5: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
            "  tv_search=TavilySearchResults(max_results=3,search_depth='advanced',max_tokens=10000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def webSearch(query:str):\n",
        "  \"\"\"this is a tool for search any information on web.\"\"\"\n",
        "  return tv_search.invoke(query)\n",
        "\n",
        "@tool\n",
        "def getWeather(query:str):\n",
        "  \"\"\"this is a tool for getting the current information of weather or environment.\"\"\"\n",
        "  BASE_URL=\"http://api.weatherapi.com/v1/current.json\"\n",
        "  comp_url=f\"{BASE_URL}?key={WEATHER_API_KEY}&q={query}\"\n",
        "  response=requests.get(comp_url)\n",
        "  data=response.json()\n",
        "  if data.get(\"location\"):\n",
        "    return data\n",
        "  else:\n",
        "    return \"Weather data not found !\"\n"
      ],
      "metadata": {
        "id": "_Vxmak9ubXUm"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_with_tool=llm.bind_tools([getWeather,webSearch])"
      ],
      "metadata": {
        "id": "A3WtXNxbdBbp"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def new_chatgpt(state:GraphState):\n",
        "  return {\"messages\":[llm_with_tool.invoke(state[\"messages\"])]}"
      ],
      "metadata": {
        "id": "0FJrS8RAj8Eh"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_graph=StateGraph(GraphState)\n",
        "new_graph.add_node(\"llm\",new_chatgpt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G02cEta-kWfT",
        "outputId": "9b618a25-47b5-4353-c997-2f0e11aff644"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7fd52e8e3f50>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import ToolNode,tools_condition\n",
        "new_graph.add_node(\"tools\",ToolNode(tools=[webSearch,getWeather]))\n",
        "new_graph.set_entry_point(\"llm\")\n",
        "new_graph.add_conditional_edges(\"llm\",tools_condition,{\"tools\":\"tools\",\"__end__\":\"__end__\"})\n",
        "new_graph.add_edge(\"tools\",\"llm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wstLDsYtkg-6",
        "outputId": "2271df2d-9095-483c-949f-edf3b1d23e4d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7fd52e8e3f50>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_agent=new_graph.compile()\n",
        "response=new_agent.invoke({\"messages\":[(\"system\",\"you are the assistant. if u don't know any information then use the associated tools.\"),(\"user\",\"give me syllabus of langgraph.\")]})\n",
        "print(response[\"messages\"][-1].content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-lbgXUDm1Y2",
        "outputId": "7eb50824-b1bc-4941-a776-aa979681c70c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The LangGraph syllabus includes a comprehensive set of topics designed to enhance your skills in AI and LLM (Large Language Model) applications. Here's a summary of the key components:\n",
            "\n",
            "1. **Core LangGraph Concepts**: Understanding chains, Directed Acyclic Graphs (DAGs), and their applications.\n",
            "2. **LangGraph vs Traditional Agents**: Building smarter, modular AI workflows.\n",
            "3. **Retrieval-Augmented Generations (RAGs) and CRAGs**: Mastering these techniques using LangGraph.\n",
            "4. **Multi-Agent Systems**: Creating complex, interactive AI agents.\n",
            "5. **Real-World Applications**: Engaging in hands-on projects to apply theoretical knowledge.\n",
            "\n",
            "For more detailed information, you can explore resources like the [YouTube video on the LangGraph course syllabus](https://www.youtube.com/watch?v=zcC8eK6grqw) or the [LangGraph tutorial on DataCamp](https://www.datacamp.com/tutorial/langgraph-tutorial).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WGI7frynCr9",
        "outputId": "c5effadd-d516-4af0-e106-6fa14f499ba9"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'messages': [SystemMessage(content=\"you are the assistant. if u don't know any information then use the associated tools.\", additional_kwargs={}, response_metadata={}, id='df1d38e8-9b97-4637-af54-7b8225f5da93'), HumanMessage(content='give me syllabus of langgraph.', additional_kwargs={}, response_metadata={}, id='c2c283ef-9842-437a-b90f-9394322a3c36'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_4sHSUqWRyDKEV5M6IMoxtBUx', 'function': {'arguments': '{\"query\":\"LangGraph syllabus\"}', 'name': 'webSearch'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 100, 'total_tokens': 116, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f33640a400', 'id': 'chatcmpl-CLPadSHgenNzVkeMOq8ha3KYAa8u5', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--480d396f-2ac0-460e-86c9-b969890d6c22-0', tool_calls=[{'name': 'webSearch', 'args': {'query': 'LangGraph syllabus'}, 'id': 'call_4sHSUqWRyDKEV5M6IMoxtBUx', 'type': 'tool_call'}], usage_metadata={'input_tokens': 100, 'output_tokens': 16, 'total_tokens': 116, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='[{\"title\": \"Syllabus Introduction of End to End LangGraph Course - YouTube\", \"url\": \"https://www.youtube.com/watch?v=zcC8eK6grqw\", \"content\": \"Are you ready to master LangGraph and take your AI and LLM skills to the next level? In this video, well walk you through the comprehensive syllabus of our End-to-End LangGraph Course, designed for developers, data scientists, and AI enthusiasts. You\\'ll get a deep dive into LangGraph essentials, learn how to build advanced RAGs (Retrieval-Augmented Generation), create multi-agent systems, and unlock the full potential of LangChain components in real-world projects.\\\\n\\\\n What You\\'ll Learn: [...] Core LangGraph Concepts: From Chains to DAGs and everything in between.\\\\nLangGraph vs Traditional Agents: Building smarter, modular AI workflows.\\\\nRAGs and CRAGs: Master Retrieval-Augmented Generations using LangGraph.\\\\nMulti-Agent Systems: Creating complex, interactive AI agents.\\\\nReal-World Applications: Hands-on projects to take your skills beyond theory.\\\\nDont miss outsubscribe now and stay ahead in the world of AI-powered development! [...] get to know about so you will get to know each and everything about these particular thing and definitely it will help you to understand the Lang graph concept now guys once I will uh like cover up this uh like basic stuff right uh then I will come to the Lang graph so here inside the Lang graph guys first I will discuss about the graph why there is a graph structure what is the requirement of the graph structure uh what is a cyclic graph a cyclic graph and whenever we are creating a graph\", \"score\": 0.8286204}, {\"title\": \"LangGraph Tutorial: What Is LangGraph and How to Use It?\", \"url\": \"https://www.datacamp.com/tutorial/langgraph-tutorial\", \"content\": \"Imagine you\\'re building a complex, multi-agent large language model (LLM) application. It\\'s exciting, but it comes with challenges: managing the state of various agents, coordinating their interactions, and handling errors effectively. This is where LangGraph can help.\\\\n\\\\nLangGraph is a library within the LangChain ecosystem designed to tackle these challenges head-on. LangGraph provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured manner. [...] # LangGraph Tutorial: What Is LangGraph and How to Use It?\\\\n\\\\nLangGraph is a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured and efficient manner.\\\\n\\\\nJun 26, 2024  路 12 min read [...] LangGraph enables us to create stateful, multi-actor applications utilizing LLMs as easily as possible. It extends the capabilities of LangChain, introducing the ability to create and manage cyclical graphs, which are pivotal for developing sophisticated agent runtimes. The core concepts of LangGraph include: graph structure, state management, and coordination.\\\\n\\\\n### Graph structure\", \"score\": 0.62879556}, {\"title\": \"Foundation: Introduction to LangGraph\", \"url\": \"https://academy.langchain.com/courses/intro-to-langgraph\", \"content\": \"1. 1. Course Overview\\\\n   2. Getting Set Up\\\\n   3. Getting Set Up (Video Guide)\\\\n   4. Module 0 Resources\\\\n2. 1. Module 1 Introduction\\\\n   2. Module 1 Resources\\\\n   3. Lesson 1: Motivation\\\\n   4. Lesson 2: Simple Graph\\\\n   5. Lesson 3: LangGraph Studio\\\\n   6. Lesson 4: Chain\\\\n   7. Lesson 5: Router\\\\n   8. Lesson 6: Agent\\\\n   9. Lesson 7: Agent with Memory\\\\n   10. [Optional] Lesson 8: Intro to Deployment\\\\n   11. Module 1 Feedback\\\\n3. 1. Module 2 Introduction\\\\n   2. Module 2 Resources [...] 7. Lesson 5: Time Travel\\\\n   8. Module 3 Feedback\\\\n5. 1. Module 4 Introduction\\\\n   2. Module 4 Resources\\\\n   3. Lesson 1: Parallelization\\\\n   4. Lesson 2: Sub-graphs\\\\n   5. Lesson 3: Map-reduce\\\\n   6. Lesson 4: Research Assistant\\\\n   7. Module 4 Feedback\\\\n6. 1. Module 5 Resources\\\\n   2. Lesson 1: Short vs. Long-Term Memory\\\\n   3. Lesson 2: LangGraph Store\\\\n   4. Lesson 3: Memory Schema + Profile\\\\n   5. Lesson 4: Memory Schema + Collection\\\\n   6. Lesson 5: Build an Agent with Long-Term Memory [...] 3. Lesson 1: State Schema\\\\n   4. Lesson 2: State Reducers\\\\n   5. Lesson 3: Multiple Schemas\\\\n   6. Lesson 4: Trim and Filter Messages\\\\n   7. Lesson 5: Chatbot w/ Summarizing Messages and Memory\\\\n   8. Lesson 6: Chatbot w/ Summarizing Messages and External Memory\\\\n   9. Module 2 Feedback\\\\n4. 1. Module 3 Introduction\\\\n   2. Module 3 Resources\\\\n   3. Lesson 1: Streaming\\\\n   4. Lesson 2: Breakpoints\\\\n   5. Lesson 3: Editing State and Human Feedback\\\\n   6. Lesson 4: Dynamic Breakpoints\", \"score\": 0.62824833}]', name='webSearch', id='99e2c572-3cf9-4821-886b-a7501128a636', tool_call_id='call_4sHSUqWRyDKEV5M6IMoxtBUx'), AIMessage(content=\"The LangGraph syllabus includes a comprehensive set of topics designed to enhance your skills in AI and LLM (Large Language Model) applications. Here's a summary of the key components:\\n\\n1. **Core LangGraph Concepts**: Understanding chains, Directed Acyclic Graphs (DAGs), and their applications.\\n2. **LangGraph vs Traditional Agents**: Building smarter, modular AI workflows.\\n3. **Retrieval-Augmented Generations (RAGs) and CRAGs**: Mastering these techniques using LangGraph.\\n4. **Multi-Agent Systems**: Creating complex, interactive AI agents.\\n5. **Real-World Applications**: Engaging in hands-on projects to apply theoretical knowledge.\\n\\nFor more detailed information, you can explore resources like the [YouTube video on the LangGraph course syllabus](https://www.youtube.com/watch?v=zcC8eK6grqw) or the [LangGraph tutorial on DataCamp](https://www.datacamp.com/tutorial/langgraph-tutorial).\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 205, 'prompt_tokens': 1315, 'total_tokens': 1520, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f33640a400', 'id': 'chatcmpl-CLPags06cLQrHqYzc7JbYeZtID5Yz', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--ce480aa0-6480-4810-8d1f-568bd82d8782-0', usage_metadata={'input_tokens': 1315, 'output_tokens': 205, 'total_tokens': 1520, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response=new_agent.invoke({\"messages\":[(\"system\",\"you are the assistant. if u don't know any information then use the associated tools.\"),(\"user\",\"give me current weather of ajmer.\")]})\n",
        "print(response[\"messages\"][-1].content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RS2ylmbNn7mb",
        "outputId": "bfbf5fbc-299e-4dda-b0bd-830988377ef7"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The current weather in Ajmer, Rajasthan, India is as follows:\n",
            "\n",
            "- **Temperature:** 30.5掳C (86.9掳F)\n",
            "- **Condition:** Moderate or heavy rain shower\n",
            "- **Wind:** 6.0 mph (9.7 kph) from the SSE\n",
            "- **Humidity:** 56%\n",
            "- **Cloud Cover:** 78%\n",
            "- **Precipitation:** 3.16 mm\n",
            "- **Feels Like:** 33.3掳C (91.9掳F)\n",
            "- **Visibility:** 7.0 km\n",
            "- **UV Index:** 7.6\n",
            "\n",
            "![Weather Icon](https://cdn.weatherapi.com/weather/64x64/day/356.png)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response[\"messages\"][2]) #tool call"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSWgraVJpXWf",
        "outputId": "4b3ddb61-e934-49cb-b11a-07c2f11e86a7"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='' additional_kwargs={'tool_calls': [{'id': 'call_Vj6ODSIdO24Nohfhvx13Hvxi', 'function': {'arguments': '{\"query\":\"Ajmer\"}', 'name': 'getWeather'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 101, 'total_tokens': 116, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f33640a400', 'id': 'chatcmpl-CLPc6ieyIXnCrrJFegmrxswmmn0nG', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--0f17bc3f-b6f8-47ec-b7fc-632ad7f54124-0' tool_calls=[{'name': 'getWeather', 'args': {'query': 'Ajmer'}, 'id': 'call_Vj6ODSIdO24Nohfhvx13Hvxi', 'type': 'tool_call'}] usage_metadata={'input_tokens': 101, 'output_tokens': 15, 'total_tokens': 116, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response=new_agent.invoke({\"messages\":[(\"system\",\"you are the assistant. if u don't know any information then use the associated tools.\"),(\"user\",\"give me more information about this city.\")]})\n",
        "print(response[\"messages\"][-1].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3A_WTXsNpmiT",
        "outputId": "4ca505a5-19e1-4fa3-efe6-a9f5420b1ccd"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could you please specify the name of the city you would like more information about?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__WE can see , out agent doesn't know about previous history of conversation.__\n",
        "# 3) Multi-user agent chatbot"
      ],
      "metadata": {
        "id": "a5TCtZAesWZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "db=InMemorySaver()"
      ],
      "metadata": {
        "id": "8ABzuNngsU2w"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_agent=new_graph.compile(checkpointer=db)"
      ],
      "metadata": {
        "id": "ps1iQo5us66V"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response=final_agent.invoke({\"messages\":[(\"system\",\"you are the assistant. if u don't know any information then use the associated tools.\"),(\"user\",\"give me current weather of ajmer.\")]}, {'configurable': { 'thread_id':\"abc123\"}})\n",
        "print(response[\"messages\"][-1].content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdCZxSGytiye",
        "outputId": "8ee5c379-07d6-4001-ba81-b78ea220d1e6"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The current weather in Ajmer, Rajasthan, India is as follows:\n",
            "\n",
            "- **Temperature:** 30.5掳C (86.9掳F)\n",
            "- **Condition:** Moderate or heavy rain shower\n",
            "- **Wind:** 6.0 mph (9.7 kph) from the SSE\n",
            "- **Humidity:** 56%\n",
            "- **Pressure:** 1003.0 mb\n",
            "- **Precipitation:** 3.16 mm\n",
            "- **Visibility:** 7.0 km\n",
            "- **UV Index:** 7.6\n",
            "- **Feels Like:** 33.3掳C (91.9掳F)\n",
            "\n",
            "![Weather Icon](//cdn.weatherapi.com/weather/64x64/day/356.png)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response=final_agent.invoke({\"messages\":[(\"system\",\"you are the assistant. if u don't know any information then use the associated tools.\"),(\"user\",\"give me more information about this city.\")]}, {'configurable': { 'thread_id':\"abc123\"}})\n",
        "print(response[\"messages\"][-1].content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WO2gU7eYtySn",
        "outputId": "588d0842-12c6-4399-8c94-a0507b1782e7"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ajmer is a city located in the north-western Indian state of Rajasthan. It serves as the administrative headquarters of the Ajmer district and division. Known as the \"Heart of Rajasthan,\" Ajmer is situated at the center of the state. Here are some key details about Ajmer:\n",
            "\n",
            "- **Location:** Ajmer is located 130 km southwest of Jaipur and 14 km from the sacred town of Pushkar. It lies among the Aravalli ranges.\n",
            "- **Historical Significance:** The city is renowned for the Ajmer Sharif Dargah, a revered Muslim shrine dedicated to the Sufi saint Moinuddin Chishti, attracting millions of pilgrims from all faiths. Another notable site is the Adhai Din Ka Jhonpra, originally a Sanskrit college transformed into a mosque in the 12th century.\n",
            "- **Cultural Heritage:** Ajmer is a vibrant blend of religions, communities, and cultures, epitomizing the diversity of Indian heritage. The city is known for its architectural wonders and spiritual legacy.\n",
            "- **Economy:** Ajmer is a trade center for salt, mica, cloth fabrics, and agricultural products. It has industries like railway workshops, oilseed mills, and is known for handicrafts, cloth weaving, and dyeing.\n",
            "- **Education:** It is home to Maharashi Dayanand Saraswati University, established in 1987.\n",
            "- **Population:** As of the 2011 census, the city had a population of 542,321.\n",
            "\n",
            "For more detailed information, you can visit the [Wikipedia page on Ajmer](https://en.wikipedia.org/wiki/Ajmer) or explore [Incredible India's page on Ajmer](https://www.incredibleindia.gov.in/en/rajasthan/ajmer).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__We can see that now our agent can remmeber the previous conversation according to session id.__"
      ],
      "metadata": {
        "id": "KH0CBjw2uTLL"
      }
    }
  ]
}